\documentclass[12pt]{article} % article?
\usepackage{geometry} %
\geometry{a4paper} % or letter or a5paper or ... etc
\usepackage{graphicx}
\usepackage{amssymb,amsmath, bm}
\geometry{letterpaper, top=1in, left=1in, right=1in, bottom=1in} % to set margins

\usepackage{setspace}
\onehalfspacing

\title{Using {\tt pomp} to model pathogen interactions}
\author{Nicholas G Reich}

%%% BEGIN DOCUMENT
\begin{document}

%opts_chunk$set(concordance=TRUE, tidy=TRUE)

\maketitle


\section{The disease transmission model}
We specify a model for a univariate time series, measured in discrete time units. Say that $Y_{i,t}$ are the number of observed cases of disease $i$ within a particular time window $t$. Furthermore, $X_{i,t}$ are the total number of cases occuring in time $t$. The theoretical transmission model (adapted from Finkenstadt and Grenfell) could be written as
\begin{equation}
X_{i,t} = \beta_t \cdot X_{i,t-1}^{\alpha_1} \cdot S_{i,t-1}^{\alpha_2}
\end{equation}
where $S_{i,t}$ is the number of susceptible individuals to disease $i$ at time $t$ and 
% lifted from supplemental materials of JRSI paper
the $\beta_t$ are a time-varying transmission parameters.  
The $\alpha$ are mixing parameters, which, if both equal 1, define a population with homogeneous mixing whereas values not equal to 1 have been used to describe departures from mass-action mixing 
%\cite{liu1987dynamical} 
and to account for discretization of continuous time transmission processes 
%\cite{glass2003interpreting}
.


Therefore, a statistical formulation of the theoretical transmission model would be
\begin{eqnarray}
\log {\mathbb E}[ X_{i,t}|X_{\cdot,t-1}, S_{i,t-1}] & = & \log\beta_t + \alpha_1 \log X_{t-1} + \alpha_2 \log S_{i,t-1}
\end{eqnarray}
where the $\beta_t$ coefficients represent the seasonal baselines, i.e. $\beta_t = \beta_{t \mod 26}$ if our timestep is biweeks, and $p_t$ are time-varying case-reporting probabilities. We intentionally leave the distributional assumption for $X_{i,t}$ unspecified for now, although it would likely be specified as Poisson or Negative Binomial.

The heart of this model resides in our definition of the $S_{i,t}$. In the past, we have defined this measure of susceptibility along these lines:
\begin{eqnarray}
S_{i,t} & = &  B_{t-d} + S_{i,t-1} - I_{i,t} - \delta \cdot Q_{-i,t} \label{eq:generalSuscModel}
%S_{i,t} & = & S_{i,t-1} + B_{t-d} - I_{i,t} -\delta\sum_{j\neq i}[I_{j,t-1}- I_{j,t-(k+1)}]. 
\end{eqnarray}
where the $Q_{-i,t}$ term may take on different forms depending on the mechanistic process assumed about how individuals enter and leave the pool of susceptible individuals based on cross-protection and enhancement. For the moment, we might assume a model with a fixed duration of cross-protection, in which case, $Q_{-i,t}(k) = \sum_{j\neq i}[I_{j,t-1}- I_{j,t-(k+1)}]$ where $Q$ depends on  $k$ is the fixed duration of cross protection.

Based on the above formulation, we can write a process simulator function based on the {\tt pomp} package format.
<<processSimulatorDefine, message=FALSE>>=
require(pomp)
proc.sim <- function(x, t, params, delta.t, ...) {
        ## unpack the params vector:
        ##  biweek
        biweek <- params["biweek"]
        beta.string <- paste0("beta", biweek)
        ## beta1, ...., beta26
        beta_t <- params[beta.string]
        ## alpha1 and alpha2
        alpha1 <- params["alpha1"]
        alpha2 <- params["alpha2"]
        ## CP params: delta and k
        delta <- params["delta"]
        k <- params["k"]
        ## state at time t:
        X <- x["X"]
        ## compute the state at time t+delta.t
        log.lambda <- beta*log(X) + alpha
        xnew <- c(X=unname( rpois(n=1, lambda=exp(log.lambda)) ))
        return(xnew)
}
@

\section{The model for an observation process}
And the observation process could be modeled as 
\begin{eqnarray}
Y_{i,t} | X_{i,t} & \sim & Binomial(p_{i,t}, X_{i,t})
%\bm{Y_t} | \bm{X_t} & \sim & Multinomial(\bm{p_t}, N_t)
\end{eqnarray}
where the $p_{i,t}$ are calculated based on, say, a standard susceptible reconstruction. It would probably even be more accurate to say that $p_{i,t}\sim Beta(a,b)$ such that the mean of the beta distribution is equal to that of the estimated $p$ from the susceptible reconstruction, and the variance is equal to that of resulting from the fit.
%some known disease-specific reporting fractions that are varying over time and $N_t$ is the total number of cases of any disease under consideration observed at time $t$. For example, we observe four under-reported serotype-specific case counts over time (the $Y_{i,t}$, or more succinctly, the $\bm{Y_t}$ and one total case count ($N_t$). Then, the $\bm{p_t}$ could be estimated by $p_{i,t} = \frac{Y_{i,t}}{N_t}$. 

\section{A two-strain cross-protection model}
%Let's start with a similar but simpler version of the model presented above:
%\begin{eqnarray}
%\log {\mathbb E}[ X_{i,t}|X_{\cdot,t-1}, S_{i,t-1}] & = & \log\beta + \alpha_1 \log X_{t-1} + \alpha_2 \log S_{i,t-1}\\
%S_{i,t} & = &  B + S_{i,t-1} - \sum_j I_{j,t} +  \\
%C_{i,t} & = &  C_{i,t-1} + \sum{j \neq i}X_{j,t} \\
%Q_{-i,t} & = &  \sum_{j\neq i}[I_{j,t-1}- I_{j,t-(k+1)}]
%\end{eqnarray}
I created a model that is similar to the theoretical four-strain model shown above but with a few major departures from the above models:
\begin{itemize}
\item Assume only two strains.
\item Assume $\beta$ is constant.
\item Assume births are constant B.
\item Assume any infected individual has an exponentially distributed duration of cross-protection, with mean $\frac{1}{\lambda}$.
\end{itemize}

\begin{table}[htdp]
\caption{Toy model parameters}
\begin{center}
\begin{tabular}{ll}
\bf parameter & \bf description \\ 
\hline
$\beta$ & contact rate \\ 
$\lambda$ & 1/mean duration of cross-protection \\
$\alpha_1$, $\alpha_2$ & mixing parameters \\ 
$N$ & population size \\
$\mu$ & birth rate \\ 
$\iota$ & rate of imported infections \\ 
\end{tabular}
\end{center}
\label{toyParams}
\end{table}%


Model parameters are shown in Table \ref{toyParams}. The model was initialized with a vector of six initial values for the $S$, $I$ and $CP$ compartments for each strain and was simulated using the following framework:
\begin{eqnarray}
I_{i,t} & \sim & Poisson\left ( \beta \cdot (\frac{I_{i,t-1}}{N}+\iota)^{\alpha_1}\cdot S_{i,t-1}^{\alpha_2}\right ) \\
NS_{i,t} & \sim & Poisson(\lambda \cdot CP_{i,t-1}) \\
S_{i,t} & = & S_{i,t-1} + N\cdot\mu - \sum_{\forall j} I_{j,t} + NS_{1,t} \\ 
CP_{i,t} & = & CP_{i,t-1} - NS_{i,t} + \sum_{j\neq i}I_{j,t} 
\end{eqnarray}
Note that the $NS$ quantity stands for ``newly susceptible'', i.e. these are the individuals who are heading out of the cross-protected state ($CP$) and back to being susceptible. The trick that we have used here is that by assuming the cross protection is exponentially distributed and by keeping track explicitly of $CP_{i,t}$ we can use the memoryless property of exponential survival to calculate how many individuals will leave the CP class only using the current count of inviduals in CP and $\lambda$. Currently am implementing this by drawing a Poisson with mean $\lambda\cdot CP_t$, but is this completely right? 

<<simpleProcSim>>=
toy.proc.sim <- function(x, t, params, delta.t, ...) {
        ## unpack the params vector:
        beta <- params["beta"]
        alpha1 <- params["alpha1"]
        alpha2 <- params["alpha2"]
        lambda <- params["lambda"]
        mu <- params["mu"]
        N <- params["N"]
        iota <- params["iota"]
        ## copy x for easy access
        newx <- x
        ## transitions for each strain
        newx["I1"] <- rpois(1, beta*((x["I1"]/N+iota)^alpha1)*(x["S1"]^alpha2))
        newx["I2"] <- rpois(1, beta*((x["I2"]/N+iota)^alpha1)*(x["S2"]^alpha2))
        ## Poisson approximation to exponential losses
        C1.loss <- rpois(1, lambda*x["C1"]) 
        C2.loss <- rpois(1, lambda*x["C2"]) 
        ## udpate counts
        newx["S1"] <- x["S1"] + N*mu - newx["I1"] - newx["I2"] + C1.loss
        newx["S2"] <- x["S2"] + N*mu - newx["I2"] - newx["I1"] + C2.loss
        newx["C1"] <- x["C1"] - C1.loss + newx["I2"]
        newx["C2"] <- x["C2"] - C2.loss + newx["I1"]
        return(newx[c("S1", "I1", "C1", "S2", "I2", "C2")])
}

toy.meas.sim <- function(x, t, params, ...) {
        rho1 <- params["rho1"]
        rho2 <- params["rho2"]
        y1 <- rbinom(1, size=x["I1"], prob=rho1)
        y2 <- rbinom(1, size=x["I2"], prob=rho2)
        unname(c(y1, y2))
}
@

And now we can simulate this framework
<<simulateToyTSIR, cache=TRUE>>=
simulate(
        pomp(
                data=data.frame(
                        time=seq(0, 5000,by=1),
                        y1=NA,
                        y2=NA
                ),
                times="time",
                t0=0,
                rprocess=discrete.time.sim(
                        step.fun=toy.proc.sim,
                        delta.t=1
                ),
                rmeasure=toy.meas.sim,
                # initial condition parameters 
                ic.pars=c("S1.0","I1.0","C1.0", 
                          "S2.0","I2.0","C2.0"), 
                # names of the compartments
                comp.names=c("S1","I1","C1", "S2","I2","C2") 
        ),
        params=c(
                N=50000,
                mu=1/500,
                rho1=.5, rho2=.1,
                beta=1.4,alpha1=1,alpha2=1,
                iota=1/10000,
                lambda=1/100,
                S1.0=40000,I1.0=100,C1.0=100,
                S2.0=40000,I2.0=100,C2.0=100
        ),
        seed=677573454L
) -> tsir
plot(tsir, variables=c("y1", "y2", "C1","C2", "I1","I2", "S1", "S2"))
@

\section{A four-strain cross-protection model}
Now, adapting the two-strain toy model above to include four strains. Again:
\begin{itemize}
\item Assume $\beta$ is constant.
\item Assume births are constant B.
\item Assume any infected individual has an exponentially distributed duration of cross-protection, with mean $\frac{1}{\lambda}$.
\end{itemize}

\begin{table}[htdp]
\caption{Toy model parameters}
\begin{center}
\begin{tabular}{ll}
\bf parameter & \bf description \\ 
\hline
$\beta$ & contact rate \\ 
$\lambda$ & 1/mean duration of cross-protection \\
$\alpha_1$, $\alpha_2$ & mixing parameters \\ 
$N$ & population size \\
$\mu$ & birth rate \\ 
$\iota$ & rate of imported infections \\ 
\end{tabular}
\end{center}
\label{toyParams}
\end{table}%


Model parameters are shown in Table \ref{toyParams}. The model was initialized with a vector of three initial values for each strain (the $S$, $I$ and $CP$ compartments for each strain) and was simulated using the following framework:
\begin{eqnarray}
I_{i,t} & \sim & Poisson\left ( (\beta(t) \frac{I_{i,t-1}}{N}+\iota)^{\alpha_1}\cdot S_{i,t-1}^{\alpha_2}\right ) \\
NS_{i,t} & \sim & Poisson(\lambda \cdot CP_{i,t-1}) \\
S_{i,t} & = & S_{i,t-1} + N\cdot\mu - \sum_{\forall j} I_{j,t} + NS_{1,t} \\ 
CP_{i,t} & = & CP_{i,t-1} - NS_{i,t} + \sum_{j\neq i}I_{j,t} 
\end{eqnarray}
Note that the $NS$ quantity stands for ``newly susceptible'', i.e. these are the individuals who are heading out of the cross-protected state ($CP$) and back to being susceptible. The trick that we have used here is that by assuming the cross protection is exponentially distributed and by keeping track explicitly of $CP_{i,t}$ we can use the memoryless property of exponential survival to calculate how many individuals will leave the CP class only using the current count of inviduals in CP and $\lambda$. Currently am implementing this by drawing a Poisson with mean $\lambda\cdot CP_t$, but is this completely right? 

Adding a seasonality b-spline basis function and plot the betas given a set of coefficients
<<seasonalityTerms>>=
tbasis <- seq(0, 100, by=1/26)
basis <- periodic.bspline.basis(tbasis,nbasis=3,degree=2,period=1,names="b%d")
basisCoefs <- c(1.5,-.1,1) ## chosen to give range between ~.2 and ~1.2
betas <- basis %*% basisCoefs
plot(betas[1:52], type="l")
@

The following functions define the simulator for the process model as well as the simulator for the measurement model: 
<<fourStrainProcSim>>=
fourStrainProcSim <- function(x, t, params, delta.t, covars, ...) {
        ## unpack the params vector:
        b <- params[c("b1", "b2", "b3")]
        beta <- b %*% covars#params["beta"]
        alpha1 <- params["alpha1"]
        alpha2 <- params["alpha2"]
        lambda <- params["lambda"]
        mu <- params["mu"]
        N <- params["N"]
        iota <- params["iota"]
        ## copy x for easy access
        newx <- x
        namesI <- c("I1", "I2", "I3", "I4")
        namesS <- c("S1", "S2", "S3", "S4")
        namesC <- c("C1", "C2", "C3", "C4")
        ## transitions for each strain
        newx[namesI] <- rpois(4, beta*((x[namesI]/N+iota)^alpha1)*(x[namesS]^alpha2))
        ## sums for newly cross-protecteds for each strain 
        sumMatrix <- 1 - diag(4) ## for strain i, sum all but i 
        NCP <- newx[namesI]%*%sumMatrix
        ## Poisson approximation to exponential losses, those moving from CP back to S
        NS <- rpois(4, lambda*x[namesC]) 
        ## udpate counts
        newx[namesS] <- pmax(x[namesS] + N*mu - sum(newx[namesI]) + NS, 0)
        newx[namesC] <- x[namesC] - NS + NCP
        return(newx[c(namesS, namesI, namesC)])
}

fourStrainMeasSim <- function(x, t, params, covars, ...) {
        namesR <- paste0("rho", 1:4)
        namesI <- paste0("I", 1:4)
        rhos <- params[namesR]
        ys <- rbinom(4, size=x[namesI], prob=rhos)
        unname(ys)
}
@

And now we can set up this pomp object for simulation with different parameter sets:
<<simulateFourStrainTSIR>>=
pomp(
        data=data.frame(
                time=seq(0, 100,by=1/26),
                y1=NA, y2=NA, y3=NA, y4=NA
        ),
        times="time",
        tcovar=tbasis,
        covar=basis,
        t0=0,
        rprocess=discrete.time.sim(
                step.fun=fourStrainProcSim,
                delta.t=1/26
        ),
        rmeasure=fourStrainMeasSim,
        # initial condition parameters 
        ic.pars=c(paste0("I", 1:4, ".0"),
                  paste0("S", 1:4, ".0"),
                  paste0("C", 1:4, ".0")
        ),
        # names of the compartments
        comp.names=c(paste0("I", 1:4),
                     paste0("S", 1:4),
                     paste0("C", 1:4)
        )
) -> tsir
@

The following simulation uses a set of parameters that generates a lot of zero observation values:
<<simulationWithZeroes>>=
paramsZeroes <- c(N=50000,
                  mu=1/500,
                  rho1=.5, rho2=.1, rho3=.1, rho4=.1,
                  b1=basisCoefs[1], 
                  b2=basisCoefs[2],  
                  b3=basisCoefs[3], 
                  #beta=1.1,
                  alpha1=1,alpha2=1,
                  iota=1/200000,
                  lambda=1/50,
                  S1.0=10000,I1.0=100,C1.0=100,
                  S2.0=10000,I2.0=100,C2.0=100,
                  S3.0=10000,I3.0=100,C3.0=100,
                  S4.0=10000,I4.0=100,C4.0=100
)
simulate(
        tsir,
        params=paramsZeroes,
        seed=677573454L
) -> tsirZeroes
plot(tsirZeroes, variables=c("I1","I2", "I3", "I4"))
plot(tsirZeroes, variables=c("S1","S2", "S3", "S4"))
@

Parameters from this simulation were chosen so that there were not as many zeroes as in the last one.
<<simulationFewerZeroes>>=
basisCoefs <- c(1.1,.95,1) ## chosen to give range between ~.2 and ~1.2
betas <- basis %*% basisCoefs
plot(betas[1:52], type="l")
paramsMore <- c(N=50000,
                mu=1/50,
                rho1=.5, rho2=.1, rho3=.1, rho4=.1,
                b1=basisCoefs[1], 
                b2=basisCoefs[2],  
                b3=basisCoefs[3], 
                alpha1=1,alpha2=1,
                iota=1/700,
                lambda=1/50,
                S1.0=100000,I1.0=100,C1.0=100,
                S2.0=100000,I2.0=100,C2.0=100,
                S3.0=100000,I3.0=100,C3.0=100,
                S4.0=100000,I4.0=100,C4.0=100
)
simulate(
        tsir,
        params=paramsMore,
        seed=677573454L
) -> tsirMore
plot(tsirMore, variables=c("I1","I2", "I3", "I4"))
#plot(tsirMore, variables=c("S1","S2", "S3", "S4"))
tsirMore <- window(tsirMore, start=30, end=100)
@


\subsection*{Measurement model}
We define measurement model as a simple binomial process for each strain:
\begin{equation}
Y_{i,t} \sim {\text Binomial}(I_{i,t}, \rho_{i,t})
\end{equation}
where $Y_{i,t}$ is the number of reported cases for strain $i$ at time $t$ and $\rho_i$ is a strain-specific reporting rate. In the code implemented above, we assume $\rho_{i,t}$ is constant over time but it could be assumed to vary across time. 

Here is the function that evaluates the measurement model pdf:
<<measModelDens>>=
fourStrainMeasDens <- function(y, x, t, params, covars, log, ...) {
        namesR <- paste0("rho", 1:4)
        namesI <- paste0("I", 1:4)
        rhos <- params[namesR]
        f <- dbinom(y, size=x[namesI], prob=rhos, log=log)
        return(unname(prod(f)))
}
tsirMore <- pomp(
             tsirMore,
             dmeasure=fourStrainMeasDens
             )
@


Before we go further, we should add in parameter transformations to see if that makes likelihood calculations, filtering, etc... more smooth.
<<paramTransforms>>=
tsirMore <- pomp(
                tsirMore,
                ## from estimation scale to natural scale
                parameter.transform=function(params,...){
                        exp.idx <- c("N", "mu", "iota", "lambda",
                                     "S1.0", "I1.0", "C1.0",
                                     "S2.0", "I2.0", "C2.0",
                                     "S3.0", "I3.0", "C3.0",
                                     "S4.0", "I4.0", "C4.0")
                        params[exp.idx] <- exp(params[exp.idx])
                        expit.idx <- paste0("rho", 1:4)
                        params[expit.idx] <- exp(params[expit.idx])/(1+exp(params[expit.idx]))
                        return(params)
                },
                ## from natural scale to estimation scale
                parameter.inv.transform=function(params,...){
                        log.idx <- c("N", "mu", "iota", "lambda",
                                     "S1.0", "I1.0", "C1.0",
                                     "S2.0", "I2.0", "C2.0",
                                     "S3.0", "I3.0", "C3.0",
                                     "S4.0", "I4.0", "C4.0")
                        params[log.idx] <- log(params[log.idx])
                        logit.idx <- paste0("rho", 1:4)
                        params[logit.idx] <- log(params[logit.idx]/(1-params[logit.idx]))
                        return(params)
                }
)
@


And now, we can define a parameter vector, and evaluate the likelihood of the simulated data from above at a particular parameter set:
<<evalLik, include=FALSE, eval=FALSE>>=
theta <- c(N=50000,
           mu=1/500,
           rho1=.5, rho2=.1, rho3=.1, rho4=.1,
           b1=basisCoefs[1],
           b2=basisCoefs[2],
           b3=basisCoefs[3],
           alpha1=1,alpha2=1,
           iota=1/200000,
           lambda=1/50,
           S1.0=10000,I1.0=100,C1.0=100,
           S2.0=10000,I2.0=100,C2.0=100,
           S3.0=10000,I3.0=100,C3.0=100,
           S4.0=10000,I4.0=100,C4.0=100)
pf <- pfilter(tsirMore, params=theta, Np=1000, max.fail=50, tol=1e-4, 
              save.states=TRUE, save.params=TRUE, verbose=TRUE)
(loglik.truth <- logLik(pf))
@
Can't get the above code to not fail!


\section{to dos}
\begin{itemize}
\item Try trajectory matching?
\item For running a particle filter, is it possible to specify certain parameters that remain fixed across all particles?
\end{itemize}

\end{document}